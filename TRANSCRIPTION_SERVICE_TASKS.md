# Transcription Service - 专砖转 砖转

##  转驻拽 住专住
转  砖 砖专 爪专转 拽爪 LRC 注 住专  拽专拽

---

##  砖转 驻转

### 1. 转 住转 驻转
- [ ] 爪专转 转拽转 `services/transcription-service/`
- [ ] 转 `Dockerfile` 住专住 (注 Python -speech recognition libraries)
- [ ] 爪专转 `requirements.txt` 注 STT -audio processing dependencies
- [ ] 专转 砖转 住 (Kafka, Elasticsearch, AI API keys)

### 2. 专转 注 Speech-to-Text

#### 驻砖专转 砖:

**Option A: OpenAI Whisper (抓)**
- [ ] 转拽转 Whisper -OpenAI
- [ ]  拽 (offline)
- [ ] 转 注 砖驻转 砖转
- [ ] 拽  拽 砖专

**Option B: Google Speech-to-Text**
- [ ] Google Cloud Speech API
- [ ] 专砖 专 专
- [ ] 注 专 驻转 拽

**Option C: Azure Speech Services**
- [ ] Microsoft Cognitive Services
- [ ] 转  
- [ ] 专砖 API key

**爪: Whisper local processing + Google backup**

### 3. Core Transcription Engine

####  转 住住
- [ ] 爪专转 `app/services/speech_to_text.py`
- [ ] 砖 `transcribe_audio(audio_path: str) -> TranscriptionResult`:

**注 Whisper:**
```python
def transcribe_with_whisper(audio_path):
    import whisper

    # Load model (once per service)
    model = whisper.load_model("base")  # tiny/base/small/medium/large

    # Transcribe with timestamps
    result = model.transcribe(
        audio_path,
        task="transcribe",
        language="auto-detect",  # or specific language
        word_timestamps=True,
        temperature=0.0  # deterministic
    )

    return {
        "segments": result["segments"],
        "language": result["language"],
        "confidence": calculate_confidence(result),
        "duration": result.get("duration", 0)
    }
```

#### 注 拽住 砖驻专
- [ ] 爪专转 `app/services/text_processor.py`
- [ ] 拽 拽住 专注砖 -artifacts
- [ ]  住 专转 (锌懈锌械胁芯胁)
- [ ] 转拽 砖转 转 驻爪转  砖 砖专
- [ ] 砖驻专 punctuation capitalization

### 4. 爪专转 拽爪 LRC

####  LRC Generator
- [ ] 爪专转 `app/services/lrc_generator.py`
- [ ] 砖 `create_lrc_file(transcription_result, output_path) -> str`:

```python
def create_lrc_file(segments, metadata, output_path):
    lrc_content = []

    # Add metadata headers
    lrc_content.append(f"[ar:{metadata.get('artist', '')}]")
    lrc_content.append(f"[ti:{metadata.get('title', '')}]")
    lrc_content.append(f"[al:{metadata.get('album', '')}]")
    lrc_content.append(f"[by:Karaoke AI System]")
    lrc_content.append("")

    # Add timed lyrics
    for segment in segments:
        start_time = format_lrc_timestamp(segment["start"])
        text = clean_text(segment["text"])
        lrc_content.append(f"[{start_time}]{text}")

    # Write to file
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lrc_content))

    return output_path
```

#### Timestamp Formatting
- [ ] 砖 `format_lrc_timestamp(seconds) -> str`:
```python
def format_lrc_timestamp(seconds):
    """Convert seconds to LRC format [mm:ss.xx]"""
    minutes = int(seconds // 60)
    remaining_seconds = seconds % 60
    return f"{minutes:02d}:{remaining_seconds:05.2f}"
```

#### 转 住专
- [ ] 拽转 overlap  segments
- [ ] /拽住 专 砖驻
- [ ] Gap detection 驻 专
- [ ] 拽  砖 砖驻 专

### 5. 专爪 注 Kafka

#### Consumer 拽砖转 转
- [ ] 爪专转 `app/consumers/transcription_consumer.py`
- [ ]  驻拽 `transcription.process.requested`
- [ ] 注 注转 驻专:
```json
{
  "video_id": "dQw4w9WgXcQ",
  "original_path": "/shared/audio/dQw4w9WgXcQ/original.mp3",
  "action": "transcribe",
  "metadata": {
    "title": "Never Gonna Give You Up",
    "artist": "Rick Astley"
  }
}
```

#### Producer  转爪转
- [ ] 爪专转 `app/services/kafka_producer.py`
- [ ] 砖转 注转 住 驻拽 `transcription.done`:
```json
{
  "video_id": "dQw4w9WgXcQ",
  "status": "transcription_done",
  "lyrics_path": "/shared/audio/dQw4w9WgXcQ/lyrics.lrc",
  "language": "en",
  "confidence": 0.92,
  "word_count": 156,
  "processing_time": 32.1,
  "segments_count": 24
}
```

### 6. 专爪 注 Elasticsearch
- [ ] 爪专转 `app/services/elasticsearch_updater.py`
- [ ] 注 住 砖专 专 转 爪:
```python
def update_song_document(video_id, lyrics_path, transcription_metadata):
    doc_update = {
        "file_paths.lyrics": lyrics_path,
        "updated_at": datetime.utcnow().isoformat(),
        "transcription_metadata": {
            "language": transcription_metadata["language"],
            "confidence": transcription_metadata["confidence"],
            "word_count": transcription_metadata["word_count"],
            "processing_time": transcription_metadata["processing_time"]
        },
        "search_text": extract_searchable_text(lyrics_path)  # for better search
    }
    es_client.update(index="songs", id=video_id, body={"doc": doc_update})
```

### 7. 注 砖驻转 驻爪

#### 专-砖转
- [ ]   砖 砖驻
- [ ] 转 注专转, 转, '
- [ ] 驻 砖转 驻爪转  砖驻
- [ ] Character encoding  (UTF-8)

#### 驻爪 拽
- [ ] Pre-processing 砖 audio (noise reduction)
- [ ]  专拽注 拽 拽
- [ ] 砖驻专 拽 拽专 砖 distortion
- [ ] Filter too short/too long segments

### 8.  拽爪 爪注

#### File Management
- [ ] 爪专转 `app/utils/file_manager.py`
- [ ] 拽 拽爪 audio 
- [ ] 拽转 转拽转 拽抓 LRC 爪专
- [ ]  cloud (驻爪)

#### Memory & Performance
- [ ] 注 拽爪 专 chunks
- [ ]  专  Whisper
- [ ] Batch processing 砖 住驻专 拽爪
- [ ] 转 住驻专 注 拽

### 9. 驻 砖转

#### Error Handling
- [ ] 驻 砖转 转:
  - 拽抓  驻/ 转
  - 砖驻  
  - 专注砖 专  (转 )
  - timeout 注
- [ ] Retry mechanism 注 驻专专 砖
- [ ] Fallback  专

#### Quality Control
- [ ] 拽转 转 转:
```python
def validate_transcription_quality(result):
    if result["confidence"] < 0.3:
        raise LowConfidenceError("Transcription confidence too low")

    if len(result["segments"]) < 5:
        raise InsufficientContentError("Too few segments detected")

    return True
```

### 10. 砖拽 专
- [ ] 爪专转 `app/main.py` 注 entry point
- [ ] 驻注转 Kafka consumer
- [ ] 拽转 专 砖专转
- [ ] Health check endpoints
- [ ] Model loading warm-up

### 11. 专 
- [ ]  驻专  砖:
  - 拽转 拽砖 Kafka
  - 转转 转
  - 转爪转 转 拽
  -  注
  - 爪专转 LRC
  - 注 Elasticsearch
- [ ] Metrics collection (拽 爪注,  注)

### 12. 拽转
- [ ] Unit tests 注 拽注  
- [ ] 拽转 转 LRC 爪专
- [ ] Integration tests 注 Kafka mock
- [ ] 拽转 拽 transcription 注 golden dataset
- [ ] Load testing 注 拽爪 专

---

##  转 专砖转

### Speech Recognition
- **openai-whisper** - 注 转 拽 转
- **speechrecognition** - wrapper 注 STT 砖
- **pydub** - 注  住住
- **librosa** - 转  转拽

### Text Processing
- **nltk**  **spacy** - 注 砖驻 注转
- **langdetect** -  砖驻
- **unidecode** - 拽 characters 

### Infrastructure
- **kafka-python** - Kafka integration
- **elasticsearch-py** - Elasticsearch updates

---

##  Dependencies 注专转

### 住 (Whisper)
```txt
openai-whisper==20231117
pydub==0.25.1
librosa==0.10.1
kafka-python==2.0.2
elasticsearch==8.11.0
langdetect==1.0.9
python-dotenv==1.0.0
nltk==3.8.1
```

### 拽住 ( 驻砖专转)
```txt
# Whisper + alternatives
openai-whisper==20231117
SpeechRecognition==3.10.0
google-cloud-speech==2.23.0
azure-cognitiveservices-speech==1.34.0

# Audio processing
pydub==0.25.1
librosa==0.10.1
soundfile==0.12.1
noisereduce==3.0.0

# Text processing
nltk==3.8.1
spacy>=3.7.0
langdetect==1.0.9
unidecode==1.3.7

# Infrastructure
kafka-python==2.0.2
elasticsearch==8.11.0
```

---

##  注专转 砖转

### Whisper Model Selection
- **tiny**: 专 (~5 砖转) 拽 
- **base**:   (~15 砖转)
- **small**: 转  (~30 砖转)
- **medium/large**: 转  转专 (~60+ 砖转)

### LRC File Format
```lrc
[ar:Rick Astley]
[ti:Never Gonna Give You Up]
[00:00.50]We're no strangers to love
[00:04.15]You know the rules and so do I
[00:08.20]A full commitment's what I'm thinking of
```

### Language Detection
- 砖驻 转 注 Whisper
- Fallback 转   
- 住驻爪驻拽 转 驻砖专转

### Docker Considerations
```dockerfile
# Install audio libraries
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libsndfile1 \
    && rm -rf /var/lib/apt/lists/*

# Download Whisper model during build
RUN python -c "import whisper; whisper.load_model('base')"
```

### Performance Tips
-  注 驻注 转 转
- 注 parallel 砖 segments
- Cache 转爪转 砖专 驻驻专

### Quality Metrics
```python
def calculate_transcription_confidence(result):
    avg_confidence = sum(s.get("confidence", 0) for s in result["segments"]) / len(result["segments"])
    return avg_confidence
```

砖专转  专砖 注 -NLP -Speech Processing!